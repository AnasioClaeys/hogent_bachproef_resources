{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import numpy as np                                  # \"Scientific computing\"\n",
    "import scipy.stats as stats                         # Statistical tests\n",
    "\n",
    "import pandas as pd                                 # Data Frame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# import matplotlib.pyplot as plt                     # Basic visualisation\n",
    "# from statsmodels.graphics.mosaicplot import mosaic  # Mosaic diagram\n",
    "# import seaborn as sns                               # Advanced data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vosk Performantie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  16.666666666666668\n",
      "Standard deviation:  1.1503622617824936\n",
      "Confidence interval:  (13.809008390033783, 19.524324943299554)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  235.0\n",
      "Standard deviation:  37.749172176353746\n",
      "Confidence interval:  (141.22585781052547, 328.77414218947456)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.7216666666666667\n",
      "Standard deviation:  0.052041649986653345\n",
      "Confidence interval:  (1.592388041354712, 1.8509452919786213)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Amerikaans-Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([16.7, 17.8, 15.5])\n",
    "memory_usage = np.array([240, 270, 195])\n",
    "recognition_speed = np.array([1.705, 1.780, 1.680])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  17.299999999999997\n",
      "Standard deviation:  0.4582575694955851\n",
      "Confidence interval:  (16.161625089935075, 18.43837491006492)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  263.3333333333333\n",
      "Standard deviation:  9.71253485622231\n",
      "Confidence interval:  (239.2060592206009, 287.46060744606575)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.7723333333333333\n",
      "Standard deviation:  0.03397548135543243\n",
      "Confidence interval:  (1.6879335588244793, 1.8567331078421874)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([16.9, 17.2, 17.8])\n",
    "memory_usage = np.array([255, 261, 274])\n",
    "recognition_speed = np.array([1.744, 1.763, 1.810])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  18.166666666666668\n",
      "Standard deviation:  0.6027713773341704\n",
      "Confidence interval:  (16.669299556685722, 19.664033776647614)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  283.3333333333333\n",
      "Standard deviation:  14.0118997046558\n",
      "Confidence interval:  (248.5258448641659, 318.14082180250074)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.8873333333333333\n",
      "Standard deviation:  0.067515430335097\n",
      "Confidence interval:  (1.7196157067149451, 2.0550509599517217)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([17.6, 18.1, 18.8])\n",
    "memory_usage = np.array([269, 284, 297])\n",
    "recognition_speed = np.array([1.819, 1.889, 1.954])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vosk Accuraatheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  11.166666666666666\n",
      "Standard deviation:  2.368255335333024\n",
      "Confidence interval:  (5.283594277184883, 17.04973905614845)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Amerikaans Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([13.46, 11.31, 8.73])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  23.459999999999997\n",
      "Standard deviation:  1.9541494313383523\n",
      "Confidence interval:  (18.605623703277093, 28.3143762967229)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([21.33, 25.17, 23.88])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  22.73\n",
      "Standard deviation:  1.8583056799138284\n",
      "Confidence interval:  (18.113712780623427, 27.346287219376574)\n"
     ]
    }
   ],
   "source": [
    "# Vosk Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([21.44, 21.89, 24.86])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Performantie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  19.333333333333332\n",
      "Standard deviation:  0.7371114795831991\n",
      "Confidence interval:  (17.502246909159314, 21.16441975750735)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  330.6666666666667\n",
      "Standard deviation:  31.533051443419385\n",
      "Confidence interval:  (252.3342244104761, 408.99910892285726)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  2.086\n",
      "Standard deviation:  0.028160255680657303\n",
      "Confidence interval:  (2.0160460468920145, 2.155953953107985)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([19.6, 19.9, 18.5])\n",
    "memory_usage = np.array([324, 365, 303])\n",
    "recognition_speed = np.array([2.055, 2.110, 2.093])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  20.666666666666668\n",
      "Standard deviation:  0.8621678104251722\n",
      "Confidence interval:  (18.52492309495883, 22.808410238374506)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  365.3333333333333\n",
      "Standard deviation:  10.016652800877813\n",
      "Confidence interval:  (340.4505883654715, 390.2160783011951)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  2.2223333333333333\n",
      "Standard deviation:  0.10674424262382184\n",
      "Confidence interval:  (1.9571659347225565, 2.48750073194411)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([19.9, 20.5, 21.6])\n",
    "memory_usage = np.array([355, 366, 375])\n",
    "recognition_speed = np.array([2.120, 2.214, 2.333])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  26.26666666666667\n",
      "Standard deviation:  1.4742229591663976\n",
      "Confidence interval:  (22.604493818318637, 29.9288395150147)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  379.6666666666667\n",
      "Standard deviation:  7.767453465154029\n",
      "Confidence interval:  (360.3712425898509, 398.96209074348246)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  2.3916666666666666\n",
      "Standard deviation:  0.07659199261889806\n",
      "Confidence interval:  (2.2014016093863167, 2.5819317239470165)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([24.6, 26.8, 27.4])\n",
    "memory_usage = np.array([371, 382, 386])\n",
    "recognition_speed = np.array([2.313, 2.396, 2.466])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Accuraatheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  13.166666666666666\n",
      "Standard deviation:  1.8079362083141468\n",
      "Confidence interval:  (8.67550415121025, 17.65782918212308)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([14.81, 13.46, 11.23])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  24.386666666666667\n",
      "Standard deviation:  0.3914502948438452\n",
      "Confidence interval:  (23.414250226981334, 25.359083106352)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([23.94, 24.67, 24.55])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  24.48\n",
      "Standard deviation:  2.7576801845029104\n",
      "Confidence interval:  (17.629542656814607, 31.330457343185394)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Whisper met TensorFlow Lite Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([22.56, 23.24, 27.64])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PocketSphinx Performantie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  19.166666666666668\n",
      "Standard deviation:  0.7767453465154026\n",
      "Confidence interval:  (17.23712425898509, 21.096209074348245)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  317.0\n",
      "Standard deviation:  23.302360395462088\n",
      "Confidence interval:  (259.1137277695526, 374.8862722304474)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.6636666666666668\n",
      "Standard deviation:  0.06789943544193373\n",
      "Confidence interval:  (1.4949951184808925, 1.8323382148524412)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([19.4, 19.8, 18.3])\n",
    "memory_usage = np.array([324, 336, 291])\n",
    "recognition_speed = np.array([1.641, 1.740, 1.610])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  19.766666666666666\n",
      "Standard deviation:  1.0016652800877812\n",
      "Confidence interval:  (17.278392169880487, 22.254941163452845)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  334.6666666666667\n",
      "Standard deviation:  28.00595174839329\n",
      "Confidence interval:  (265.096025775885, 404.2373075574484)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.7563333333333333\n",
      "Standard deviation:  0.03464582706955243\n",
      "Confidence interval:  (1.6702683277561443, 1.8423983389105223)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([18.8, 19.7, 20.8])\n",
    "memory_usage = np.array([307, 334, 363])\n",
    "recognition_speed = np.array([1.720, 1.760, 1.789])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage\n",
      "Mean:  21.8\n",
      "Standard deviation:  1.705872210923198\n",
      "Confidence interval:  (17.562378509471284, 26.037621490528718)\n",
      "\n",
      "Memory Usage\n",
      "Mean:  362.3333333333333\n",
      "Standard deviation:  17.009801096230763\n",
      "Confidence interval:  (320.078644961338, 404.58802170532863)\n",
      "\n",
      "Recognition Speed\n",
      "Mean:  1.8743333333333332\n",
      "Standard deviation:  0.06232442004008803\n",
      "Confidence interval:  (1.719510891150701, 2.0291557755159655)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "cpu_usage = np.array([20.4, 21.3, 23.7])\n",
    "memory_usage = np.array([343, 369, 375])\n",
    "recognition_speed = np.array([1.816, 1.867, 1.940])\n",
    "\n",
    "# Averages\n",
    "cpu_mean = np.mean(cpu_usage)\n",
    "memory_mean = np.mean(memory_usage)\n",
    "recognition_speed_mean = np.mean(recognition_speed)\n",
    "\n",
    "# Standard deviations\n",
    "cpu_std = np.std(cpu_usage, ddof=1)\n",
    "memory_std = np.std(memory_usage, ddof=1)\n",
    "recognition_speed_std = np.std(recognition_speed, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(cpu_usage)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "cpu_ci = (cpu_mean - t_critical * cpu_std / np.sqrt(n), cpu_mean + t_critical * cpu_std / np.sqrt(n))\n",
    "memory_ci = (memory_mean - t_critical * memory_std / np.sqrt(n), memory_mean + t_critical * memory_std / np.sqrt(n))\n",
    "recognition_speed_ci = (recognition_speed_mean - t_critical * recognition_speed_std / np.sqrt(n), recognition_speed_mean + t_critical * recognition_speed_std / np.sqrt(n))\n",
    "\n",
    "\n",
    "# FIRST PRINT CPU numbers\n",
    "print(\"CPU Usage\")\n",
    "print(\"Mean: \", cpu_mean)\n",
    "print(\"Standard deviation: \", cpu_std)\n",
    "print(\"Confidence interval: \", cpu_ci)\n",
    "\n",
    "# SECOND PRINT MEMORY numbers\n",
    "print(\"\\nMemory Usage\")\n",
    "print(\"Mean: \", memory_mean)\n",
    "print(\"Standard deviation: \", memory_std)\n",
    "print(\"Confidence interval: \", memory_ci)\n",
    "\n",
    "# THIRD PRINT RECOGNITION SPEED numbers\n",
    "print(\"\\nRecognition Speed\")\n",
    "print(\"Mean: \", recognition_speed_mean)\n",
    "print(\"Standard deviation: \", recognition_speed_std)\n",
    "print(\"Confidence interval: \", recognition_speed_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PocketSphinx Accuraatheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  12.67\n",
      "Standard deviation:  1.0160216533125666\n",
      "Confidence interval:  (10.146062295082611, 15.193937704917388)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Engels model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([13.81, 12.34, 11.86])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  23.72666666666667\n",
      "Standard deviation:  1.2720193918857265\n",
      "Confidence interval:  (20.566795325244772, 26.886538008088568)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Frans model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([22.28, 24.67, 24.23])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  23.88\n",
      "Standard deviation:  1.3931259813814398\n",
      "Confidence interval:  (20.419283212474063, 27.340716787525935)\n"
     ]
    }
   ],
   "source": [
    "# PocketSphinx Nederlands model\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for Word Error Rate (WER) of the American English model\n",
    "wer_data = np.array([22.76, 23.44, 25.44])\n",
    "\n",
    "# Calculate the mean WER\n",
    "wer_mean = np.mean(wer_data)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "wer_std = np.std(wer_data, ddof=1)\n",
    "\n",
    "# Sample size\n",
    "n = len(wer_data)\n",
    "\n",
    "# Confidence interval calculation (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "wer_ci = (wer_mean - t_critical * wer_std / np.sqrt(n), wer_mean + t_critical * wer_std / np.sqrt(n))\n",
    "\n",
    "wer_mean, wer_std, wer_ci\n",
    "\n",
    "print(\"Mean: \", wer_mean)\n",
    "print(\"Standard deviation: \", wer_std)\n",
    "print(\"Confidence interval: \", wer_ci)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
